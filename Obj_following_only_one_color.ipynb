{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"../Picture/logo.png\" alt=\"Header\" style=\"width: 800px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@Copyright (C): 2010-2021, Shenzhen Yahboom Tech  \n",
    "@Author: ZiDan  \n",
    "@Date: 2021-08-30    \n",
    "@LastEditors: ZiDan    \n",
    "@LastEditTime: 2021-08-30 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object following - basic version\n",
    "\n",
    "In this example, we will show how to use jetbotmini to track objects!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import related packages and create camera instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from jetbotmini import Camera\n",
    "from jetbotmini import bgr8_to_jpeg\n",
    "camera = Camera.instance(width=300, height=300)\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an array that stores HSV gamut color classification data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "global color_lower\n",
    "global color_upper\n",
    "global searching_target \n",
    "global approaching_target \n",
    "global cycle_done \n",
    "searching_target = 1\n",
    "approaching_target = 0\n",
    "cycle_done = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set to recognize red array data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_lower=np.array([0,43,46])\n",
    "color_upper = np.array([10, 255, 255])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_lower=np.array([20,43,46])\n",
    "color_upper = np.array([34, 255, 255])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_lower=np.array([0,120,255])\n",
    "color_upper = np.array([20, 200, 255])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Control the robot to follow the central object\n",
    "\n",
    "Now, we want the robot to follow the color of the specified class. To this end, we will do the following work\n",
    "\n",
    "1.  Detect color\n",
    "2.  Select the object closest to the center of the camera's field of view, which is the target object\n",
    "3.  Guide the robot to move towards the target object, otherwise it will drift\n",
    "\n",
    "We will also create some widgets to control the speed and turning gain of the robot, and control the turning speed of the robot according to the distance between the target object and the center of the robot's field of view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define 5 different triplets and their corresponding color names\n",
    "lower_color_bounds = np.array([\n",
    "    #blue\n",
    "     [100, 100, 100],\n",
    "    #green\n",
    "     [35, 43, 46],\n",
    "    #yellow\n",
    "     [21, 80, 80],\n",
    "    #orange\n",
    "     [13,100,100],\n",
    "    #red\n",
    "     [0,90,90],\n",
    "    #purple\n",
    "    [129,70,70]\n",
    "])\n",
    "upper_color_bounds = np.array([\n",
    "    #blue\n",
    "    [128, 255, 255],\n",
    "    #green\n",
    "    [80, 255, 255],\n",
    "    #yellow\n",
    "    [35, 255, 255],\n",
    "    #orange\n",
    "    [20, 255, 255],\n",
    "    #red\n",
    "    [7,255,255],\n",
    "    #purple\n",
    "    [170,255,255]\n",
    "])\n",
    "\n",
    "color_lower = lower_color_bounds[0]\n",
    "color_upper = upper_color_bounds[0]\n",
    "color_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import traitlets\n",
    "import ipywidgets.widgets as widgets\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "\n",
    "mean = 255.0 * np.array([0.485, 0.456, 0.406])\n",
    "stdev = 255.0 * np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "normalize = torchvision.transforms.Normalize(mean, stdev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a robot instance that drives the motor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetbotmini import Robot\n",
    "\n",
    "robot = Robot()\n",
    "\n",
    "# Function to rotate the robot slowly\n",
    "def rotate_robot():\n",
    "    robot.left(0.3)\n",
    "    \n",
    "def rotate_robot_fast():\n",
    "    robot.right(0.6)\n",
    "    \n",
    "# Function to stop the robot\n",
    "def stop_robot():\n",
    "    robot.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's display all the control widgets and connect the network execution function to the camera update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dd12b6aa8204b7ca034bff0be21256c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Image(value=b'', format='jpeg', height='300', width='300'),)), FloatSlider(valueâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from jetbotmini import bgr8_to_jpeg\n",
    "\n",
    "color_index = 0\n",
    "image_widget = widgets.Image(format='jpeg', width=300, height=300)\n",
    "speed_widget = widgets.FloatSlider(value=0.4, min=0.0, max=1.0, description='speed')\n",
    "turn_gain_widget = widgets.FloatSlider(value=0.5, min=0.0, max=2.0, description='turn gain')\n",
    "center_x = 0\n",
    "display(widgets.VBox([\n",
    "    widgets.HBox([image_widget]),\n",
    "    speed_widget,\n",
    "    turn_gain_widget\n",
    "]))\n",
    "width = int(image_widget.width)\n",
    "height = int(image_widget.height)      \n",
    "def execute(change):\n",
    "    global color_lower, color_upper, color_index, approaching_target, searching_target, cycle_done\n",
    "    \n",
    "    color_upper_np = np.array(color_upper)\n",
    "    color_lower_np = np.array(color_lower)\n",
    "    # Get new frame from the camera, fit it to size 300*300 pixels and add Gaussian noise \n",
    "    frame = camera.value\n",
    "    frame = cv2.resize(frame, (300, 300))\n",
    "    frame =cv2.GaussianBlur(frame,(5,5),0)  \n",
    "    # Get hsv values of the frame and filter out any parts of the frame not within the range of the current searched colour. \n",
    "    hsv=cv2.cvtColor(frame,cv2.COLOR_BGR2HSV)\n",
    "    mask=cv2.inRange(hsv,color_lower_np,color_upper_np)  \n",
    "    # Use opening operator(erode+dilate) to smooth contours and separate objects from each other\n",
    "    mask=cv2.erode(mask,None,iterations=2)\n",
    "    mask=cv2.dilate(mask,None,iterations=2)\n",
    "    mask=cv2.GaussianBlur(mask,(3,3),0)   \n",
    "    # Detect all objects which fit the current colour in the frame\n",
    "    cnts=cv2.findContours(mask.copy(),cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)[-2] \n",
    "    # Control jetbotmini to follow the set object\n",
    "    if len(cnts)>0:\n",
    "        cnt = max (cnts,key=cv2.contourArea) \n",
    "        (color_x,color_y),color_radius=cv2.minEnclosingCircle(cnt)\n",
    "        # If the largest object of our colour is within our size bounds, start approaching it\n",
    "        if (color_radius > 10) & (color_radius < 100):\n",
    "            #Set state to Approaching Target\n",
    "            approaching_target = 1\n",
    "            searching_target = 0\n",
    "            # Mark the detected color\n",
    "            cv2.circle(frame,(int(color_x),int(color_y)),int(color_radius),(255,0,255),2)  \n",
    "            # Correct location according to the error between the middle of the frame and the middle of the object\n",
    "            center_x = (150 - color_x)/150\n",
    "            robot.set_motors(\n",
    "                float(speed_widget.value - turn_gain_widget.value * center_x),\n",
    "                float(speed_widget.value + turn_gain_widget.value * center_x)\n",
    "            )    \n",
    "        # If the object was reached, move to the next colour\n",
    "        elif (color_radius >= 100):\n",
    "            #If target was just reached, stop and change state to start searching\n",
    "            if (approaching_target):\n",
    "                stop_robot()\n",
    "                approaching_target = 0\n",
    "                searching_target = 1  \n",
    "                if (color_index == len(lower_color_bounds) - 1):\n",
    "                    if not cycle_done:\n",
    "                        rotate_robot_fast()\n",
    "                        time.sleep(5)\n",
    "                        cycle_done = 1\n",
    "                    stop_robot()\n",
    "                    time.sleep(10)\n",
    "                color_index = (color_index + 1)%len(lower_color_bounds)\n",
    "                color_lower= lower_color_bounds[color_index]\n",
    "                color_upper = upper_color_bounds[color_index]\n",
    "                cycle_done = 0\n",
    "            rotate_robot()\n",
    "        else:\n",
    "            rotate_robot()\n",
    "    # If no target is detected, rotate\n",
    "    else:\n",
    "        rotate_robot()\n",
    "     \n",
    "    # Update image display to widget\n",
    "    image_widget.value = bgr8_to_jpeg(frame)  \n",
    "execute({'new': camera.value})\n",
    "#if (searching_target):\n",
    " #   stop_robot()\n",
    "  #  time.sleep(5)\n",
    "   # rotate_robot()\n",
    "    #time.sleep(5)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the following block to connect the execution function to each camera frame update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.unobserve_all()\n",
    "camera.observe(execute, names='value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the target is found, the robot should turn to the target.\n",
    "You can call the following code block to manually disconnect the processing from the camera and stop the robot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "camera.unobserve_all()\n",
    "time.sleep(1.0)\n",
    "robot.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
